#!/usr/bin/env python3
"""
ì¸í”Œë£¨ì–¸ì„œ ì „ìš© QA ìƒì„± ì„œë¹„ìŠ¤
speech_generatorì™€ generate_qa ë¡œì§ì„ í™œìš©í•˜ì—¬ ì¸í”Œë£¨ì–¸ì„œë³„ 2000ìŒì˜ QA ìƒì„±
"""

import json
import os
import time
import random
import tempfile
from typing import List, Dict, Optional
from openai import OpenAI
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
from sqlalchemy.orm import Session

from app.database import get_db
from app.services.influencers.crud import get_influencer_by_id
from app.services.batch_job_service import get_batch_job_service
from pipeline.speech_generator import CharacterProfile, Gender, SpeechGenerator


class QAGenerationStatus(Enum):
    PENDING = "pending"
    PROCESSING = "processing"  
    BATCH_SUBMITTED = "batch_submitted"
    BATCH_PROCESSING = "batch_processing"
    BATCH_COMPLETED = "batch_completed"
    PROCESSING_RESULTS = "processing_results"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class QAGenerationTask:
    task_id: str
    influencer_id: str
    status: QAGenerationStatus
    batch_id: Optional[str] = None
    total_qa_pairs: int = 2000
    generated_qa_pairs: int = 0
    error_message: Optional[str] = None
    s3_urls: Optional[Dict] = None
    created_at: datetime = None
    updated_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.updated_at is None:
            self.updated_at = datetime.now()


class InfluencerQAGenerator:
    def __init__(self, api_key: Optional[str] = None):
        """
        ì¸í”Œë£¨ì–¸ì„œìš© QA ìƒì„±ê¸°
        Args:
            api_key: OpenAI API í‚¤
        """
        self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
        self.speech_generator = SpeechGenerator(api_key)
        self.batch_service = get_batch_job_service()
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ tasksëŠ” ì›¹í›… ëª¨ë“œì—ì„œë§Œ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
        self.tasks: Dict[str, QAGenerationTask] = {}
        
    def influencer_to_character_profile(self, influencer_data: dict, style_preset: dict = None, mbti: dict = None) -> CharacterProfile:
        """
        ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ë¥¼ CharacterProfileë¡œ ë³€í™˜
        Args:
            influencer_data: DBì—ì„œ ê°€ì ¸ì˜¨ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°
            style_preset: ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ë°ì´í„°
            mbti: MBTI ë°ì´í„°
        Returns:
            CharacterProfile ê°ì²´
        """
        # ì„±ë³„ ë§¤í•‘ (influencer_gender: 1=ë‚¨ì„±, 2=ì—¬ì„±, 3=ì¤‘ì„±)
        gender_map = {
            1: Gender.MALE,
            2: Gender.FEMALE, 
            3: Gender.NON_BINARY
        }
        
        # ë‚˜ì´ëŒ€ ë§¤í•‘ (influencer_age_group: 1=10ëŒ€, 2=20ëŒ€, 3=30ëŒ€, 4=40ëŒ€, 5=50ëŒ€+)
        age_group_map = {
            1: 15,  # 10ëŒ€
            2: 25,  # 20ëŒ€  
            3: 35,  # 30ëŒ€
            4: 45,  # 40ëŒ€
            5: 55   # 50ëŒ€+
        }
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        name = influencer_data.get('influencer_name', 'ì¸í”Œë£¨ì–¸ì„œ')
        description = influencer_data.get('influencer_description', '')
        
        # ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ì—ì„œ ì •ë³´ ì¶”ì¶œ
        if style_preset:
            gender = gender_map.get(style_preset.get('influencer_gender', 3), Gender.NON_BINARY)
            age = age_group_map.get(style_preset.get('influencer_age_group', 2), 25)
            personality = style_preset.get('influencer_personality', 'ì¹œê·¼í•˜ê³  í™œë°œí•œ ì„±ê²©')
            
            # ì„¤ëª…ì— ìŠ¤íƒ€ì¼ ì •ë³´ ì¶”ê°€
            if not description:
                hairstyle = style_preset.get('influencer_hairstyle', '')
                style = style_preset.get('influencer_style', '')
                speech = style_preset.get('influencer_speech', '')
                description = f"í—¤ì–´ìŠ¤íƒ€ì¼: {hairstyle}, ìŠ¤íƒ€ì¼: {style}, ë§íˆ¬: {speech}"
        else:
            gender = Gender.NON_BINARY
            age = 25
            personality = 'ì¹œê·¼í•˜ê³  í™œë°œí•œ ì„±ê²©'
            
        # MBTI ì •ë³´ ì¶”ì¶œ
        if mbti:
            mbti_type = mbti.get('mbti_name', 'ENFP')
            # ì„±ê²©ì— MBTI íŠ¹ì„± ì¶”ê°€
            mbti_traits = mbti.get('mbti_traits', '')
            if mbti_traits:
                personality += f" ({mbti_traits})"
        else:
            mbti_type = 'ENFP'  # ê¸°ë³¸ê°’
            
        return CharacterProfile(
            name=name,
            description=description,
            age=age,
            gender=gender,
            personality=personality,
            mbti=mbti_type
        )
    
    def create_qa_batch_requests(self, character: CharacterProfile, num_requests: int = 2000) -> List[Dict]:
        """
        ì¸í”Œë£¨ì–¸ì„œ ìºë¦­í„°ë¥¼ ìœ„í•œ QA ìƒì„± ë°°ì¹˜ ìš”ì²­ ìƒì„±
        Args:
            character: ìºë¦­í„° í”„ë¡œí•„
            num_requests: ìƒì„±í•  QA ê°œìˆ˜
        Returns:
            ë°°ì¹˜ ìš”ì²­ ë¦¬ìŠ¤íŠ¸
        """
        # ë‹¤ì–‘í•œ ì§ˆë¬¸ ì£¼ì œë“¤
        question_topics = [
            "ì¼ìƒìƒí™œê³¼ ì·¨ë¯¸",
            "íŒ¨ì…˜ê³¼ ë·°í‹°",
            "ì—¬í–‰ê³¼ ë§›ì§‘",
            "ì—°ì• ì™€ ê´€ê³„",
            "ì§ì—…ê³¼ ì»¤ë¦¬ì–´", 
            "ê±´ê°•ê³¼ ìš´ë™",
            "ë¬¸í™”ì™€ ì—”í„°í…Œì¸ë¨¼íŠ¸",
            "ì†Œì…œë¯¸ë””ì–´ì™€ íŠ¸ë Œë“œ",
            "ìê¸°ê³„ë°œê³¼ ì„±ì¥",
            "ê°€ì¡±ê³¼ ì¹œêµ¬ë“¤",
            "ì‡¼í•‘ê³¼ ì†Œë¹„",
            "ìŒì‹ê³¼ ìš”ë¦¬",
            "ìŠ¤íŠ¸ë ˆìŠ¤ì™€ íë§",
            "ë¯¸ë˜ì™€ ê¿ˆ",
            "ì¶”ì–µê³¼ ê²½í—˜"
        ]
        
        requests = []
        
        # ìºë¦­í„° í”„ë¡¬í”„íŠ¸ ìƒì„±
        character_prompt = self.speech_generator.create_character_prompt(character)
        
        for i in range(num_requests):
            topic = random.choice(question_topics)
            
            request = {
                "custom_id": f"influencer_qa_{character.name}_{i+1}",
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": "gpt-4o-mini",
                    "messages": [
                        {
                            "role": "system",
                            "content": character_prompt
                        },
                        {
                            "role": "user",
                            "content": f"'{topic}' ì£¼ì œì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ì„ í•˜ë‚˜ ë§Œë“¤ê³ , ë‹¹ì‹ ì˜ ìºë¦­í„°ì™€ ë§íˆ¬ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. í˜•ì‹: Q: [ì§ˆë¬¸] A: [ë‹µë³€]"
                        }
                    ],
                    "max_tokens": 300,
                    "temperature": 0.8
                }
            }
            requests.append(request)
        
        return requests
    
    def save_batch_file(self, requests: List[Dict], task_id: str) -> str:
        """ë°°ì¹˜ ìš”ì²­ì„ JSONL íŒŒì¼ë¡œ ì €ì¥"""
        filename = f"influencer_qa_batch_{task_id}.jsonl"
        # OSì— ë§ëŠ” ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        temp_dir = tempfile.gettempdir()
        filepath = os.path.join(temp_dir, filename)
        
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„±
        os.makedirs(temp_dir, exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for request in requests:
                f.write(json.dumps(request, ensure_ascii=False) + '\n')
        
        print(f"ë°°ì¹˜ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filepath}")
        return filepath
    
    def submit_batch_job(self, batch_file_path: str, task_id: str) -> str:
        """OpenAI ë°°ì¹˜ ì‘ì—… ì œì¶œ"""
        print(f"ë°°ì¹˜ íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {batch_file_path}")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        with open(batch_file_path, 'rb') as f:
            batch_input_file = self.client.files.create(
                file=f,
                purpose="batch"
            )
        
        print(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {batch_input_file.id}")
        
        # ëª¨ë‹ˆí„°ë§ ë°©ì‹ í™•ì¸
        use_webhook = os.getenv('OPENAI_USE_WEBHOOK', 'true').lower() == 'true'
        
        batch_create_params = {
            "input_file_id": batch_input_file.id,
            "endpoint": "/v1/chat/completions",
            "completion_window": "24h",
            "metadata": {
                "description": f"Influencer QA pairs generation - Task ID: {task_id}",
                "task_id": task_id
            }
        }
        
        # ì›¹í›… ëª¨ë“œì¼ ë•Œë§Œ ì›¹í›… URL ì¶”ê°€
        if use_webhook:
            webhook_url = os.getenv('OPENAI_WEBHOOK_URL', 'http://localhost:8000/api/v1/influencers/webhooks/openai/batch-complete')
            batch_create_params["metadata"]["webhook_url"] = webhook_url
            print(f"ğŸ¯ ì›¹í›… ëª¨ë“œë¡œ ë°°ì¹˜ ì‘ì—… ìƒì„± ì¤‘...")
        else:
            print(f"ğŸ”„ í´ë§ ëª¨ë“œë¡œ ë°°ì¹˜ ì‘ì—… ìƒì„± ì¤‘...")
        
        # ë°°ì¹˜ ì‘ì—… ìƒì„±
        batch = self.client.batches.create(**batch_create_params)
        
        print(f"ë°°ì¹˜ ì‘ì—… ìƒì„± ì™„ë£Œ: {batch.id}")
        return batch.id
    
    def check_batch_status(self, batch_id: str) -> Dict:
        """ë°°ì¹˜ ì‘ì—… ìƒíƒœ í™•ì¸"""
        batch = self.client.batches.retrieve(batch_id)
        return {
            "id": batch.id,
            "status": batch.status,
            "request_counts": batch.request_counts.__dict__ if batch.request_counts else None,
            "created_at": batch.created_at,
            "completed_at": batch.completed_at,
            "output_file_id": batch.output_file_id if hasattr(batch, 'output_file_id') else None,
            "error_file_id": batch.error_file_id if hasattr(batch, 'error_file_id') else None
        }
    
    def download_batch_results(self, batch_id: str, task_id: str) -> Optional[str]:
        """ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
        batch = self.client.batches.retrieve(batch_id)
        
        if batch.status != "completed":
            print(f"ë°°ì¹˜ ì‘ì—…ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ: {batch.status}")
            return None
        
        if not batch.output_file_id:
            print("ì¶œë ¥ íŒŒì¼ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        result_file_name = f"influencer_qa_results_{task_id}.jsonl"
        temp_dir = tempfile.gettempdir()
        result_file_path = os.path.join(temp_dir, result_file_name)
        
        file_response = self.client.files.content(batch.output_file_id)
        
        with open(result_file_path, 'wb') as f:
            f.write(file_response.content)
        
        print(f"ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {result_file_path}")
        return result_file_path
    
    def process_qa_results(self, result_file_path: str) -> List[Dict]:
        """ê²°ê³¼ íŒŒì¼ì—ì„œ QA ìŒ ì¶”ì¶œ"""
        qa_pairs = []
        
        with open(result_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                result = json.loads(line)
                
                if result.get('response', {}).get('status_code') == 200:
                    content = result['response']['body']['choices'][0]['message']['content']
                    
                    # Q: A: í˜•ì‹ìœ¼ë¡œ íŒŒì‹±
                    if 'Q:' in content and 'A:' in content:
                        try:
                            parts = content.split('A:', 1)
                            if len(parts) == 2:
                                question = parts[0].replace('Q:', '').strip()
                                answer = parts[1].strip()
                                
                                qa_pairs.append({
                                    "question": question,
                                    "answer": answer,
                                    "custom_id": result.get('custom_id')
                                })
                        except Exception as e:
                            print(f"QA íŒŒì‹± ì˜¤ë¥˜: {e}")
                            continue
        
        return qa_pairs
    
    def save_qa_pairs_to_db(self, influencer_id: str, qa_pairs: List[Dict], db: Session):
        """ìƒì„±ëœ QA ìŒì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        # TODO: QA ìŒì„ ì €ì¥í•  í…Œì´ë¸”ì´ í•„ìš” (ì˜ˆ: influencer_qa_pairs)
        # í˜„ì¬ëŠ” JSON íŒŒì¼ë¡œ ì„ì‹œ ì €ì¥
        filename = f"influencer_{influencer_id}_qa_pairs.json"
        temp_dir = tempfile.gettempdir()
        filepath = os.path.join(temp_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(qa_pairs, f, ensure_ascii=False, indent=2)
        
        print(f"QA ìŒ {len(qa_pairs)}ê°œê°€ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def start_qa_generation(self, influencer_id: str, db: Session) -> str:
        """
        ì¸í”Œë£¨ì–¸ì„œë¥¼ ìœ„í•œ QA ìƒì„± ì‹œì‘
        Args:
            influencer_id: ì¸í”Œë£¨ì–¸ì„œ ID
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        Returns:
            ì‘ì—… ID
        """
        # ì‘ì—… ID ìƒì„±
        task_id = f"qa_{influencer_id}_{int(time.time())}"
        
        # ì›¹í›… ëª¨ë“œì—ì„œëŠ” ë©”ëª¨ë¦¬ì—ë„ ì €ì¥ (í•˜ìœ„ í˜¸í™˜ì„±)
        use_webhook = os.getenv('OPENAI_USE_WEBHOOK', 'true').lower() == 'true'
        if use_webhook:
            task = QAGenerationTask(
                task_id=task_id,
                influencer_id=influencer_id,
                status=QAGenerationStatus.PENDING
            )
            self.tasks[task_id] = task
            print(f"ì›¹í›… ëª¨ë“œ: ë©”ëª¨ë¦¬ì— ì‘ì—… ì €ì¥: task_id={task_id}")
        
        try:
            # ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            user_id = "system"  # ì‹œìŠ¤í…œ ì‘ì—…ìœ¼ë¡œ ì²˜ë¦¬
            influencer_data = get_influencer_by_id(db, user_id, influencer_id)
            
            if not influencer_data:
                raise Exception(f"ì¸í”Œë£¨ì–¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {influencer_id}")
            
            # ì¸í”Œë£¨ì–¸ì„œ â†’ ìºë¦­í„° í”„ë¡œí•„ ë³€í™˜
            character = self.influencer_to_character_profile(
                influencer_data.__dict__,
                influencer_data.style_preset.__dict__ if influencer_data.style_preset else None,
                influencer_data.mbti.__dict__ if influencer_data.mbti else None
            )
            
            # ë°°ì¹˜ ìš”ì²­ ìƒì„±
            if use_webhook:
                task.status = QAGenerationStatus.PROCESSING
            
            requests = self.create_qa_batch_requests(character, 2000)
            
            # ë°°ì¹˜ íŒŒì¼ ì €ì¥
            batch_file_path = self.save_batch_file(requests, task_id)
            
            # ë°°ì¹˜ ì‘ì—… ì œì¶œ
            batch_id = self.submit_batch_job(batch_file_path, task_id)
            
            # DBì— ë°°ì¹˜ ì‘ì—… ì €ì¥
            batch_job = self.batch_service.create_batch_job(
                db=db,
                task_id=task_id,
                influencer_id=influencer_id,
                openai_batch_id=batch_id,
                input_file_id=batch_file_path  # ì…ë ¥ íŒŒì¼ ê²½ë¡œ ì €ì¥
            )
            
            # ì›¹í›… ëª¨ë“œì—ì„œëŠ” ë©”ëª¨ë¦¬ ìƒíƒœë„ ì—…ë°ì´íŠ¸
            if use_webhook:
                task.batch_id = batch_id
                task.status = QAGenerationStatus.BATCH_SUBMITTED
                task.updated_at = datetime.now()
            
            print(f"QA ìƒì„± ì‘ì—… ì‹œì‘ë¨ - Task ID: {task_id}, Batch ID: {batch_id}")
            return task_id
            
        except Exception as e:
            error_msg = str(e)
            print(f"QA ìƒì„± ì‘ì—… ì‹¤íŒ¨: {error_msg}")
            import traceback
            print(f"ìƒì„¸ ì—ëŸ¬ ì •ë³´: {traceback.format_exc()}")
            
            # ì›¹í›… ëª¨ë“œì—ì„œëŠ” ë©”ëª¨ë¦¬ ìƒíƒœë„ ì—…ë°ì´íŠ¸
            if use_webhook and task_id in self.tasks:
                self.tasks[task_id].status = QAGenerationStatus.FAILED
                self.tasks[task_id].error_message = error_msg
                self.tasks[task_id].updated_at = datetime.now()
            
            # QA ìƒì„± ì‘ì—…ì—ì„œëŠ” ì˜ˆì™¸ë¥¼ re-raiseí•˜ì§€ ì•ŠìŒ
            return task_id
    
    def get_task_status(self, task_id: str) -> Optional[QAGenerationTask]:
        """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
        print(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ: task_id={task_id}")
        print(f"í˜„ì¬ ì €ì¥ëœ ì‘ì—… ìˆ˜: {len(self.tasks)}")
        print(f"ì €ì¥ëœ ì‘ì—… IDë“¤: {list(self.tasks.keys())}")
        
        task = self.tasks.get(task_id)
        if task:
            print(f"ì‘ì—… ì°¾ìŒ: status={task.status.value}")
        else:
            print(f"ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        return task
    
    def update_task_status(self, task_id: str):
        """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸ (ë°°ì¹˜ ìƒíƒœ í™•ì¸)"""
        task = self.tasks.get(task_id)
        if not task or not task.batch_id:
            return
        
        try:
            batch_status = self.check_batch_status(task.batch_id)
            
            if batch_status['status'] == 'completed':
                task.status = QAGenerationStatus.BATCH_COMPLETED
            elif batch_status['status'] == 'failed':
                task.status = QAGenerationStatus.FAILED
                task.error_message = "ë°°ì¹˜ ì‘ì—… ì‹¤íŒ¨"
            elif batch_status['status'] in ['validating', 'in_progress']:
                task.status = QAGenerationStatus.BATCH_PROCESSING
            
            task.updated_at = datetime.now()
            
        except Exception as e:
            task.status = QAGenerationStatus.FAILED
            task.error_message = f"ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {str(e)}"
            task.updated_at = datetime.now()
    
    def complete_qa_generation(self, task_id: str, db: Session) -> bool:
        """QA ìƒì„± ì™„ë£Œ ì²˜ë¦¬"""
        task = self.tasks.get(task_id)
        if not task or task.status != QAGenerationStatus.BATCH_COMPLETED:
            return False
        
        try:
            task.status = QAGenerationStatus.PROCESSING_RESULTS
            
            # ë°°ì¹˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
            result_file_path = self.download_batch_results(task.batch_id, task_id)
            if not result_file_path:
                raise Exception("ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            
            # QA ìŒ ì²˜ë¦¬
            qa_pairs = self.process_qa_results(result_file_path)
            
            # DBì— ì €ì¥
            self.save_qa_pairs_to_db(task.influencer_id, qa_pairs, db)
            
            # ì‘ì—… ì™„ë£Œ
            task.status = QAGenerationStatus.COMPLETED
            task.generated_qa_pairs = len(qa_pairs)
            task.updated_at = datetime.now()
            
            print(f"QA ìƒì„± ì™„ë£Œ - Task ID: {task_id}, QA ìŒ: {len(qa_pairs)}ê°œ")
            return True
            
        except Exception as e:
            task.status = QAGenerationStatus.FAILED
            task.error_message = f"ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
            task.updated_at = datetime.now()
            print(f"QA ìƒì„± ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return False