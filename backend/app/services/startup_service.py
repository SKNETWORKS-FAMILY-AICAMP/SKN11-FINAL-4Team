#!/usr/bin/env python3
"""
μ• ν”λ¦¬μΌ€μ΄μ… μ‹μ‘μ‹ μ‹¤ν–‰λλ” μ„λΉ„μ¤
QA λ°μ΄ν„°κ°€ μμ§€λ§ νμΈνλ‹μ΄ μ‹μ‘λμ§€ μ•μ€ μ‘μ—…λ“¤μ„ μλ™μΌλ΅ μ²λ¦¬
"""

import asyncio
import logging
from typing import List
from sqlalchemy.orm import Session

from app.database import get_db
from app.services.batch_job_service import get_batch_job_service
from app.services.finetuning_service import get_finetuning_service
from app.models.batch_job import BatchJob

# λ΅κΉ… μ„¤μ •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class StartupService:
    """μ• ν”λ¦¬μΌ€μ΄μ… μ‹μ‘μ‹ μ‹¤ν–‰λλ” μ„λΉ„μ¤"""
    
    def __init__(self):
        self.batch_service = get_batch_job_service()
        self.finetuning_service = get_finetuning_service()
    
    async def check_and_restart_finetuning(self) -> int:
        """
        QA λ°μ΄ν„°κ°€ μ—…λ΅λ“λμ—μ§€λ§ νμΈνλ‹μ΄ μ‹μ‘λμ§€ μ•μ€ μ‘μ—…λ“¤μ„ μ°Ύμ•„ μλ™ μ‹μ‘
        Returns:
            μ¬μ‹μ‘λ νμΈνλ‹ μ‘μ—… μ
        """
        try:
            logger.info("π” μ‹μ‘μ‹ νμΈνλ‹ μ¬μ‹μ‘ κ°€λ¥ μ‘μ—… κ²€μƒ‰ μ¤‘...")
            
            # λ°μ΄ν„°λ² μ΄μ¤ μ„Έμ… νλ“
            db: Session = next(get_db())
            
            try:
                # QA μ™„λ£λμ—μ§€λ§ νμΈνλ‹ μ‹μ‘ μ•λ μ‘μ—…λ“¤ μ°ΎκΈ°
                restart_candidates = db.query(BatchJob).filter(
                    BatchJob.status == "completed",  # QA μƒμ„± μ™„λ£
                    BatchJob.is_uploaded_to_s3 == True,  # S3 μ—…λ΅λ“ μ™„λ£
                    BatchJob.is_finetuning_started == False,  # νμΈνλ‹ μ•„μ§ μ‹μ‘ μ•λ¨
                    BatchJob.s3_qa_file_url.isnot(None)  # S3 URL μ΅΄μ¬
                ).all()
                
                if not restart_candidates:
                    logger.info("β… μ¬μ‹μ‘ν•  νμΈνλ‹ μ‘μ—…μ΄ μ—†μµλ‹λ‹¤")
                    return 0
                
                logger.info(f"π― μ¬μ‹μ‘ λ€μƒ νμΈνλ‹ μ‘μ—… {len(restart_candidates)}κ° λ°κ²¬")
                
                restarted_count = 0
                
                for batch_job in restart_candidates:
                    try:
                        logger.info(f"π€ νμΈνλ‹ μλ™ μ¬μ‹μ‘: task_id={batch_job.task_id}, influencer_id={batch_job.influencer_id}")
                        
                        # νμΈνλ‹ μ‹μ‘
                        success = await self.finetuning_service.start_finetuning_for_influencer(
                            influencer_id=batch_job.influencer_id,
                            s3_qa_file_url=batch_job.s3_qa_file_url,
                            db=db
                        )
                        
                        if success:
                            # νμΈνλ‹ μ‹μ‘ ν‘μ‹
                            self.batch_service.mark_finetuning_started(db, batch_job.task_id)
                            restarted_count += 1
                            logger.info(f"β… νμΈνλ‹ μλ™ μ¬μ‹μ‘ μ™„λ£: task_id={batch_job.task_id}")
                        else:
                            logger.warning(f"β οΈ νμΈνλ‹ μλ™ μ¬μ‹μ‘ μ‹¤ν¨: task_id={batch_job.task_id}")
                    
                    except Exception as e:
                        logger.error(f"β νμΈνλ‹ μ¬μ‹μ‘ μ¤‘ μ¤λ¥: task_id={batch_job.task_id}, error={str(e)}")
                        continue
                
                if restarted_count > 0:
                    logger.info(f"π‰ μ΄ {restarted_count}κ°μ νμΈνλ‹ μ‘μ—… μλ™ μ¬μ‹μ‘ μ™„λ£")
                else:
                    logger.warning("β οΈ μ¬μ‹μ‘ λ€μƒμ΄ μμ—μ§€λ§ λ¨λ‘ μ‹¤ν¨ν–μµλ‹λ‹¤")
                
                return restarted_count
            
            finally:
                db.close()
        
        except Exception as e:
            logger.error(f"β νμΈνλ‹ μ¬μ‹μ‘ κ²€μ‚¬ μ¤‘ μ¤λ¥: {str(e)}", exc_info=True)
            return 0
    
    async def cleanup_old_batch_jobs(self) -> int:
        """μ¤λλ λ°°μΉ μ‘μ—… μ •λ¦¬"""
        try:
            logger.info("π§Ή μ¤λλ λ°°μΉ μ‘μ—… μ •λ¦¬ μ¤‘...")
            
            db: Session = next(get_db())
            
            try:
                # 7μΌ μ΄μƒ λ μ‹¤ν¨ μ‘μ—… μ •λ¦¬
                cleaned_count = self.batch_service.cleanup_old_failed_jobs(db, days_old=7)
                
                if cleaned_count > 0:
                    logger.info(f"π—‘οΈ {cleaned_count}κ°μ μ¤λλ μ‹¤ν¨ μ‘μ—… μ •λ¦¬ μ™„λ£")
                
                return cleaned_count
            
            finally:
                db.close()
        
        except Exception as e:
            logger.error(f"β λ°°μΉ μ‘μ—… μ •λ¦¬ μ¤‘ μ¤λ¥: {str(e)}", exc_info=True)
            return 0
    
    async def run_startup_tasks(self):
        """μ‹μ‘μ‹ μ‹¤ν–‰ν•  λ¨λ“  μ‘μ—…λ“¤"""
        logger.info("π€ μ• ν”λ¦¬μΌ€μ΄μ… μ‹μ‘μ‹ μ‘μ—… μ‹¤ν–‰ μ¤‘...")
        
        try:
            # 1. νμΈνλ‹ μ¬μ‹μ‘ κ²€μ‚¬
            restarted_count = await self.check_and_restart_finetuning()
            
            # 2. μ¤λλ λ°°μΉ μ‘μ—… μ •λ¦¬
            cleaned_count = await self.cleanup_old_batch_jobs()
            
            logger.info(f"β… μ‹μ‘μ‹ μ‘μ—… μ™„λ£ - μ¬μ‹μ‘: {restarted_count}κ°, μ •λ¦¬: {cleaned_count}κ°")
            
        except Exception as e:
            logger.error(f"β μ‹μ‘μ‹ μ‘μ—… μ‹¤ν–‰ μ¤‘ μ¤λ¥: {str(e)}", exc_info=True)


# κΈ€λ΅λ² μ‹μ‘μ‹ μ„λΉ„μ¤ μΈμ¤ν„΄μ¤
startup_service = StartupService()


def get_startup_service() -> StartupService:
    """μ‹μ‘μ‹ μ„λΉ„μ¤ μμ΅΄μ„± μ£Όμ…"""
    return startup_service


async def run_startup_tasks():
    """μ• ν”λ¦¬μΌ€μ΄μ… μ‹μ‘μ‹ μ‹¤ν–‰ν•  μ‘μ—…λ“¤"""
    service = get_startup_service()
    await service.run_startup_tasks()